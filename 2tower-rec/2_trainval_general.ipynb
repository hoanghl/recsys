{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import Module\n",
    "from torch import Tensor\n",
    "from polars import DataFrame\n",
    "from loguru import logger\n",
    "from lightning.pytorch.callbacks import RichProgressBar, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "# from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data/processed/ml-1m/train_temporal-loo.parquet\")\n",
    "train = pl.read_parquet(path)\n",
    "\n",
    "path = Path(\"data/processed/ml-1m/test_temporal-loo.parquet\")\n",
    "test = pl.read_parquet(path)\n",
    "\n",
    "path = Path(\"data/processed/ml-1m/ml-1m_items.parquet\")\n",
    "items = pl.read_parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_N_GENRES = 9\n",
    "DEVICE = torch.device(\"mps\")\n",
    "BSZ = 500\n",
    "N_EPOCHS = 20\n",
    "\n",
    "N_USERS = 6041\n",
    "N_ITEMS = 3953\n",
    "N_GENRES = 19\n",
    "MAX_N_GENRES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRS(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inters: DataFrame,\n",
    "        genre_pad_id: int = 18,\n",
    "        is_training: bool = True\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.genre_pad_id = genre_pad_id\n",
    "        self.inters_pos = inters.filter(pl.col('is_positive'))\n",
    "        self.inters_neg = inters.filter(~pl.col('is_positive'))\n",
    "        self.n_sample = 1 if is_training else 100\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inters_pos)\n",
    "    \n",
    "    def _pad(self, t: list) -> Tensor:\n",
    "        num_pad = MAX_N_GENRES - len(t)\n",
    "        return F.pad(torch.tensor(t), (0, num_pad), value=self.genre_pad_id)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row_pos = self.inters_pos.row(index, named=True)\n",
    "        # rows_neg = (\n",
    "        #     self.inters_neg\n",
    "        #     .filter(pl.col('user_id') == row_pos['user_id'])\n",
    "        #     .sample(self.n_sample)\n",
    "        #     .to_dicts()\n",
    "        # )\n",
    "\n",
    "        item_id_pos = torch.tensor(row_pos['item_id']).unsqueeze(0)\n",
    "        # item_id_neg = torch.tensor([r['item_id'] for r in rows_neg])\n",
    "        genre_id_pos = self._pad(row_pos['genre_id']).unsqueeze(0)\n",
    "        pad_genre_pos = (genre_id_pos != self.genre_pad_id).int()\n",
    "        # genre_id_neg = torch.vstack([self._pad(r['genre_id']) for r in rows_neg])\n",
    "        # pad_genre_neg = (genre_id_neg != self.genre_pad_id).int()\n",
    "    \n",
    "\n",
    "        return {\n",
    "            'user_id': row_pos['user_id'],\n",
    "            'item_id_pos': item_id_pos,\n",
    "            # 'item_id_neg': item_id_neg,\n",
    "            'genre_id_pos': genre_id_pos,\n",
    "            'pad_genre_pos': pad_genre_pos,\n",
    "            # 'genre_id_neg': genre_id_neg,\n",
    "            # 'pad_genre_neg': pad_genre_neg,\n",
    "        }\n",
    "\n",
    "# ds_test = DatasetRS(test, is_training=True)\n",
    "# ds_test[10]\n",
    "# loader_test = DataLoader(ds_test, batch_size=BSZ, shuffle=True)\n",
    "# for r in loader_test:\n",
    "#     break\n",
    "\n",
    "# for k, v in r.items():\n",
    "#     print(f\"{k} --> {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "from torchmetrics.retrieval import RetrievalMRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = tensor([0, 0, 0, 0])\n",
    "preds = tensor([0.6, 0.5, 0.4, .3])\n",
    "target = tensor([0, 0, 1, 0])\n",
    "mrr = RetrievalMRR()\n",
    "mrr(preds, target, indexes=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([\n",
    "    [0., 0, 1, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 0, 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((a.cumsum(dim=-1) / (torch.arange(a.shape[-1]) + 1) ) * a).sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
>>>>>>> e70c043 (Add code for 2-tower and ColBERT)
   "source": [
    "def _get_neg_sample(batch: dict[str, Tensor]):\n",
    "    item_id_pos = batch['item_id_pos']      # [bz, 1]\n",
    "    genre_id_pos = batch['genre_id_pos']    # [bz, 1, n]\n",
    "    pad_genre_pos = batch['pad_genre_pos']  # [bz, 1, n]\n",
    "\n",
    "    bz, _, n = genre_id_pos.shape\n",
    "\n",
    "\n",
    "    # Get negative items' id\n",
<<<<<<< HEAD
    "    items_neg = item_id_pos.T.repeat(BSZ, 1)\n",
    "    items_neg = items_neg[~torch.eye(*items_neg.shape, dtype = torch.bool)].view(BSZ, BSZ-1)\n",
=======
    "    items_neg = item_id_pos.T.repeat(bz, 1)\n",
    "    items_neg = items_neg[~torch.eye(*items_neg.shape, dtype = torch.bool)].view(bz, bz-1)\n",
>>>>>>> e70c043 (Add code for 2-tower and ColBERT)
    "    # [bz, bz-1]\n",
    "\n",
    "    # Get corresponding gerne and pad of negative items\n",
    "    genre_id_neg = genre_id_pos.permute(1, 0, 2).repeat(bz, 1, 1)\n",
    "    genre_id_neg = genre_id_neg[~torch.eye(bz, dtype=torch.bool).unsqueeze(-1).repeat(1, 1, n)].view(bz, bz-1, n)\n",
    "    # [bz, bz-1, n]\n",
    "\n",
    "    pad_genre_neg = pad_genre_pos.permute(1, 0, 2).repeat(bz, 1, 1)\n",
    "    pad_genre_neg = pad_genre_neg[~torch.eye(bz, dtype=torch.bool).unsqueeze(-1).repeat(1, 1, n)].view(bz, bz-1, n)\n",
    "    # [bz, bz-1, n]\n",
    "\n",
    "    return items_neg, genre_id_neg, pad_genre_neg\n",
    "\n",
    "\n",
    "def _calc_ndcg(relevances: Tensor, k: int) -> float:\n",
    "    indices = 1 / torch.log2(torch.arange(2, relevances.shape[-1] + 2, device=relevances.device)).unsqueeze(0)\n",
    "\n",
    "    ndcg = torch.mean(relevances @ indices.T).item()\n",
    "\n",
    "    return ndcg\n",
    "\n",
    "def _calc_mrr(relevances: Tensor, k: int) -> float:\n",
    "    vals = 1 / ((relevances.argmax(dim=-1) + 1) * relevances.max(dim=-1).values) \n",
    "    vals = vals.masked_fill(vals == torch.inf, 0)\n",
    "    mrr = torch.mean(vals)\n",
    "\n",
    "    return mrr\n",
    "\n",
    "def _calc_map(relevances: Tensor, k: int) -> float:\n",
    "    val_map = ((relevances.cumsum(dim=-1) / (torch.arange(relevances.shape[-1]) + 1) ) * a).sum(-1).mean()\n",
    "    return val_map\n",
    "\n",
    "class Block(Module):\n",
    "    def __init__(self, n: int, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Linear(n, n),\n",
    "            nn.LayerNorm(n),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.LayerNorm(n),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        out = self.seq2(self.seq1(X) + X)\n",
    "\n",
    "        return out\n",
    "\n",
    "class TwoTower(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        n_items: int,\n",
    "        n_genres: int,\n",
    "        d_hid: int = 128,\n",
    "        n_blocks: int = 2,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embd_users = nn.Embedding(n_users, d_hid)\n",
    "        self.embd_items = nn.Embedding(n_items, d_hid)\n",
    "        self.embd_genres = nn.Embedding(n_genres, d_hid)\n",
    "\n",
    "        self.block_user = nn.ModuleList([Block(d_hid)] * n_blocks)\n",
    "        self.block_item = nn.ModuleList([Block(d_hid)] * n_blocks)\n",
    "        self.lin1 = nn.Linear(2 * d_hid, d_hid)\n",
    "\n",
    "        # self.ff1 = nn.Sequential(\n",
    "        #     nn.Linear(4 * d_hid, 4 * d_hid),\n",
    "        #     nn.LayerNorm(4 * d_hid),\n",
    "        #     nn.GELU(),\n",
    "        # )\n",
    "        self.lin2 = nn.Linear(4 * d_hid, 1)\n",
    "\n",
    "    def forward(self,\n",
    "        users: Tensor,\n",
    "        items: Tensor,\n",
    "        genres: Tensor,\n",
    "        pads: Tensor\n",
    "    ) -> Tensor:\n",
<<<<<<< HEAD
    "        # TODO: HoangLe [Jan-22]: Continue modifying this to match with data\n",
=======
>>>>>>> e70c043 (Add code for 2-tower and ColBERT)
    "        # users: [bz]\n",
    "        # items: [bz, l]\n",
    "        # genres, pads: [bz, l, MAX_N_GENRES]\n",
    "\n",
    "        ##################################\n",
    "        # Step 1: Embed\n",
    "        ##################################\n",
    "        users = self.embd_users(users)\n",
    "        # [bz, d_hid]\n",
    "\n",
    "        items = self.embd_items(items)\n",
    "        # [bz, l, d_hid]\n",
    "        genres = self.embd_genres(genres)\n",
    "        # [bz,, l, MAX_N_GENRES, d_hid]\n",
    "        genres = (genres * pads.unsqueeze(-1)).sum(dim=2)\n",
    "        # [bz, l, d_hid]\n",
    "\n",
    "        items = torch.concat([items, genres], dim=-1)\n",
    "        # [bz, l,  2 * d_hid]\n",
    "\n",
    "        ##################################\n",
    "        # Step 2: Block\n",
    "        ##################################\n",
    "        for block in self.block_user:\n",
    "            users = block(users)\n",
    "            # [bz, d_hid]\n",
    "\n",
    "        items = self.lin1(items)\n",
    "        # [bz, l, d_hid]\n",
    "        for block in self.block_item:\n",
    "            items = block(items)\n",
    "            # [bz, l, d_hid]\n",
    "\n",
    "        ##################################\n",
    "        # Step 3: Alignment\n",
    "        ##################################\n",
    "        # aligned = torch.concat([users, items, users - items, users * items], dim=-1)\n",
    "        # [bz, 4 * d_hid]\n",
    "        # aligned = self.ff1(aligned)\n",
    "        # logit = F.sigmoid(self.lin2(aligned))\n",
    "\n",
    "        users = users.unsqueeze(1)\n",
    "        # [bz, 1, d_hid]\n",
    "        items = items.transpose(1, 2)\n",
    "        # [bz, d_hid, l]\n",
    "\n",
    "        logger.debug(f\"users: {users.shape}\")\n",
    "        logger.debug(f\"items: {items.shape}\")\n",
    "  \n",
    "        aligned = (users @ items).squeeze(1)\n",
    "        # [bz, l]\n",
    "\n",
    "        return aligned\n",
    "\n",
    "class LitTwoTower(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_hid: int = 128,\n",
    "        n_blocks: int = 2,\n",
    "        lr: float = 1e-4,\n",
    "        criterion: Literal[\"BPR\", \"LogLoss\"] = \"BPR\",\n",
    "        k: int = 5,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "        self.model = TwoTower(N_USERS, N_ITEMS, N_GENRES, d_hid=d_hid, n_blocks=n_blocks)\n",
    "        self.criterion = criterion\n",
    "\n",
    "        self.ndcg = []\n",
    "        self.k = k\n",
    "\n",
    "    def _calc_loss(self, scores_pos: Tensor, scores_neg: Tensor, THETA: float = 1e-9) -> Tensor:\n",
    "        match (self.criterion):\n",
    "            case \"BPR\":\n",
    "                distance = torch.clamp(scores_pos - scores_neg, THETA)\n",
    "                loss = -torch.sum(torch.log(F.sigmoid(distance)))\n",
    "            case \"LogLoss\":\n",
<<<<<<< HEAD
    "                # TODO: HoangLe [Feb-13]: Implement this\n",
=======
    "                \n",
>>>>>>> e70c043 (Add code for 2-tower and ColBERT)
    "                pass\n",
    "            case _:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx) -> Tensor:\n",
    "        # Get in-batch negative samples\n",
    "        items_neg, genre_id_neg, pad_genre_neg = _get_neg_sample(batch)\n",
    "\n",
    "        scores_pos = self.model(batch['user_id'], batch['item_id_pos'], batch['genre_id_pos'], batch['pad_genre_pos'])\n",
    "        scores_neg = self.model(batch['user_id'], items_neg, genre_id_neg, pad_genre_neg)\n",
    "\n",
    "        loss = self._calc_loss(scores_pos, scores_neg)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True, on_step=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "        return optimizer\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Get in-batch negative samples\n",
    "        items_neg, genre_id_neg, pad_genre_neg = _get_neg_sample(batch)\n",
    "\n",
    "        scores_pos = self.model(batch['user_id'], batch['item_id_pos'], batch['genre_id_pos'], batch['pad_genre_pos'])\n",
    "        scores_neg = self.model(batch['user_id'], items_neg, genre_id_neg, pad_genre_neg)\n",
    "\n",
    "        scores = torch.concat([scores_pos, scores_neg], dim=-1)\n",
    "\n",
    "        # Calculate evaluation metrics\n",
    "        relevances = torch.zeros_like(scores, device=scores.device)\n",
    "        relevances[:, 0] = 1\n",
    "\n",
    "        relevances_sorted = relevances[:, torch.argsort(scores, dim=-1, descending=True)][0, :, : self.k]\n",
    "\n",
    "        val_ndcg = _calc_ndcg(relevances_sorted, self.k)\n",
    "        val_mrr = _calc_mrr(relevances_sorted, self.k)\n",
    "        val_map = _calc_map(relevances_sorted, self.k)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.log(\"val_ndcg\", val_ndcg, on_epoch=True, prog_bar=False)\n",
    "        self.log(\"val_mrr\", val_mrr, on_epoch=True, prog_bar=False)\n",
    "        self.log(\"val_map\", val_map, on_epoch=True, prog_bar=False)\n",
    "\n",
    "# ds = DatasetRS(test, is_training=False)\n",
    "# loader = DataLoader(ds, batch_size=BSZ, shuffle=True)\n",
    "# for x in loader:\n",
    "#     break\n",
    "# model = TwoTower(N_USERS, N_ITEMS, N_GENRES)\n",
    "# scores_pos = model(x['user_id'], x['item_id_pos'], x['genre_id_pos'], x['pad_genre_pos'])\n",
    "# scores_neg = model(x['user_id'], x['item_id_neg'], x['genre_id_neg'], x['pad_genre_neg'])"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
>>>>>>> e70c043 (Add code for 2-tower and ColBERT)
   "source": [
    "loader_train = DataLoader(DatasetRS(train), batch_size=BSZ, shuffle=True,)\n",
    "loader_val = DataLoader(DatasetRS(test, is_training=False), batch_size=BSZ)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = AdamW(model.parameters())\n",
    "litmodel = LitTwoTower()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"mps\",\n",
    "    devices=1,\n",
    "    max_epochs=N_EPOCHS,\n",
    "    callbacks=[RichProgressBar(leave=True)],\n",
    "    logger=TensorBoardLogger(\"tb_logs\", name=\"two_tower\", version=datetime.now().strftime(\"%m%d-%H%M%S\")),\n",
    "    check_val_every_n_epoch=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train() \n",
    "\n",
    "# for epch in range(1, N_EPOCHS + 1):\n",
    "#     for x in loader_train:\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         out = model(x['user'], x['product'], x['genres'], x['pad'], x['price'])\n",
    "#         tgt = torch.ones_like(out, device=DEVICE, dtype=torch.float32)\n",
    "\n",
    "#         loss = criterion(out, tgt)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         logger.info(f\"loss: {loss.item():.4f}\")\n",
    "\n",
    "trainer.fit(litmodel, train_dataloaders=loader_train, val_dataloaders=loader_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
