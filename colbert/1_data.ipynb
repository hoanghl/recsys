{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hoangle/Projects/recsys\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import polars as pl\n",
    "from transformers import AutoTokenizer\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MODEL_NAME': 'bert-base-cased',\n",
       " 'Nq': 32,\n",
       " 'PATH_TOKENIZER': 'colbert/processed/tokenizer',\n",
       " 'RAW_DATA': {'query': 'data/raw/hotpotqa/queries.jsonl',\n",
       "  'corpus': 'data/raw/hotpotqa/corpus.jsonl',\n",
       "  'train': 'data/raw/hotpotqa/qrels/train.tsv',\n",
       "  'val': 'data/raw/hotpotqa/qrels/dev.tsv',\n",
       "  'test': 'data/raw/hotpotqa/qrels/test.tsv'},\n",
       " 'PROCESSED': {'query': 'colbert/processed/query_tokenized.parquet',\n",
       "  'corpus': 'colbert/processed/corpus_tokenized_[i].parquet'},\n",
       " 'TOKEN': {'query': '[Q]', 'document': '[D]'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"colbert/configs.yaml\"\n",
    "\n",
    "with open(path) as file:\n",
    "    conf = yaml.safe_load(file)\n",
    "\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>_id</th><th>text</th><th>metadata</th></tr><tr><td>str</td><td>str</td><td>struct[2]</td></tr></thead><tbody><tr><td>&quot;5ab6d31155429954757d3384&quot;</td><td>&quot;What country of origin does Ho…</td><td>{&quot;American&quot;,[[&quot;House of Cosbys&quot;, &quot;0&quot;], [&quot;Bill Cosby&quot;, &quot;0&quot;]]}</td></tr><tr><td>&quot;5ac0d92f554299012d1db645&quot;</td><td>&quot;How many fountains where prese…</td><td>{&quot;1,200 musical water fountains&quot;,[[&quot;Steve Davison&quot;, &quot;0&quot;], [&quot;Steve Davison&quot;, &quot;1&quot;], … [&quot;World of Color&quot;, &quot;2&quot;]]}</td></tr><tr><td>&quot;5abd01335542993a06baf9fc&quot;</td><td>&quot;Chris Larceny directed the mus…</td><td>{&quot;the Fugees&quot;,[[&quot;Chris Larceny&quot;, &quot;3&quot;], [&quot;Wyclef Jean&quot;, &quot;0&quot;], [&quot;Wyclef Jean&quot;, &quot;2&quot;]]}</td></tr><tr><td>&quot;5abff8c95542994516f4555c&quot;</td><td>&quot;The person where local traditi…</td><td>{&quot;the Iroquois Confederacy&quot;,[[&quot;Cross Lake&quot;, &quot;1&quot;], [&quot;Hiawatha&quot;, &quot;0&quot;]]}</td></tr><tr><td>&quot;5adec8ad55429975fa854f8f&quot;</td><td>&quot;The actor who played Carl Swee…</td><td>{&quot;Denise DeClue&quot;,[[&quot;About Last Night (1986 film)&quot;, &quot;1&quot;], [&quot;Tim Kazurinsky&quot;, &quot;0&quot;]]}</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌──────────────────────────┬─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ _id                      ┆ text                            ┆ metadata                        │\n",
       "│ ---                      ┆ ---                             ┆ ---                             │\n",
       "│ str                      ┆ str                             ┆ struct[2]                       │\n",
       "╞══════════════════════════╪═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ 5ab6d31155429954757d3384 ┆ What country of origin does Ho… ┆ {\"American\",[[\"House of Cosbys… │\n",
       "│ 5ac0d92f554299012d1db645 ┆ How many fountains where prese… ┆ {\"1,200 musical water fountain… │\n",
       "│ 5abd01335542993a06baf9fc ┆ Chris Larceny directed the mus… ┆ {\"the Fugees\",[[\"Chris Larceny… │\n",
       "│ 5abff8c95542994516f4555c ┆ The person where local traditi… ┆ {\"the Iroquois Confederacy\",[[… │\n",
       "│ 5adec8ad55429975fa854f8f ┆ The actor who played Carl Swee… ┆ {\"Denise DeClue\",[[\"About Last… │\n",
       "└──────────────────────────┴─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = pl.read_ndjson(conf['RAW_DATA']['query'])\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOK_QUERY = conf['TOKEN']['query']\n",
    "TOK_DOC = conf['TOKEN']['document']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add special tokens to queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>qid</th><th>text</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;5ab6d31155429954757d3384&quot;</td><td>&quot;[CLS] [Q] What country of orig…</td></tr><tr><td>&quot;5ac0d92f554299012d1db645&quot;</td><td>&quot;[CLS] [Q] How many fountains w…</td></tr><tr><td>&quot;5abd01335542993a06baf9fc&quot;</td><td>&quot;[CLS] [Q] Chris Larceny direct…</td></tr><tr><td>&quot;5abff8c95542994516f4555c&quot;</td><td>&quot;[CLS] [Q] The person where loc…</td></tr><tr><td>&quot;5adec8ad55429975fa854f8f&quot;</td><td>&quot;[CLS] [Q] The actor who played…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────────────┬─────────────────────────────────┐\n",
       "│ qid                      ┆ text                            │\n",
       "│ ---                      ┆ ---                             │\n",
       "│ str                      ┆ str                             │\n",
       "╞══════════════════════════╪═════════════════════════════════╡\n",
       "│ 5ab6d31155429954757d3384 ┆ [CLS] [Q] What country of orig… │\n",
       "│ 5ac0d92f554299012d1db645 ┆ [CLS] [Q] How many fountains w… │\n",
       "│ 5abd01335542993a06baf9fc ┆ [CLS] [Q] Chris Larceny direct… │\n",
       "│ 5abff8c95542994516f4555c ┆ [CLS] [Q] The person where loc… │\n",
       "│ 5adec8ad55429975fa854f8f ┆ [CLS] [Q] The actor who played… │\n",
       "└──────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = (\n",
    "    queries\n",
    "    .select(\n",
    "        pl.col('_id').alias('qid'),\n",
    "        pl.format(\"[CLS] [Q] {}\", pl.col('text')).alias('text')\n",
    "    )\n",
    ")\n",
    "\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize or load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-02-22 11:32:38.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mTokenizer found. Load pre-trained.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "path_tokenizer = Path(conf['PATH_TOKENIZER'])\n",
    "\n",
    "if not path_tokenizer.exists():\n",
    "    logger.info(\"Tokenizer not found. Create new one.\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(conf['MODEL_NAME'])\n",
    "    tokenizer.add_tokens([TOK_DOC, TOK_QUERY], special_tokens=False)\n",
    "    tokenizer.add_special_tokens({'pad_token': tokenizer.mask_token})\n",
    "else:\n",
    "    logger.info(\"Tokenizer found. Load pre-trained.\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path_tokenizer)\n",
    "\n",
    "    tokenizer.save_pretrained(path_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_tokenized = tokenizer(\n",
    "    queries['text'].to_list(),\n",
    "    add_special_tokens=False,\n",
    "    padding_side='right',\n",
    "    max_length=conf['Nq'],\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='np'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>qid</th><th>text</th><th>tok_ids</th></tr><tr><td>str</td><td>str</td><td>array[i64, 32]</td></tr></thead><tbody><tr><td>&quot;5ab6d31155429954757d3384&quot;</td><td>&quot;[CLS] [Q] What country of orig…</td><td>[101, 28997, … 103]</td></tr><tr><td>&quot;5ac0d92f554299012d1db645&quot;</td><td>&quot;[CLS] [Q] How many fountains w…</td><td>[101, 28997, … 3635]</td></tr><tr><td>&quot;5abd01335542993a06baf9fc&quot;</td><td>&quot;[CLS] [Q] Chris Larceny direct…</td><td>[101, 28997, … 5110]</td></tr><tr><td>&quot;5abff8c95542994516f4555c&quot;</td><td>&quot;[CLS] [Q] The person where loc…</td><td>[101, 28997, … 103]</td></tr><tr><td>&quot;5adec8ad55429975fa854f8f&quot;</td><td>&quot;[CLS] [Q] The actor who played…</td><td>[101, 28997, … 103]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌──────────────────────────┬─────────────────────────────────┬──────────────────────┐\n",
       "│ qid                      ┆ text                            ┆ tok_ids              │\n",
       "│ ---                      ┆ ---                             ┆ ---                  │\n",
       "│ str                      ┆ str                             ┆ array[i64, 32]       │\n",
       "╞══════════════════════════╪═════════════════════════════════╪══════════════════════╡\n",
       "│ 5ab6d31155429954757d3384 ┆ [CLS] [Q] What country of orig… ┆ [101, 28997, … 103]  │\n",
       "│ 5ac0d92f554299012d1db645 ┆ [CLS] [Q] How many fountains w… ┆ [101, 28997, … 3635] │\n",
       "│ 5abd01335542993a06baf9fc ┆ [CLS] [Q] Chris Larceny direct… ┆ [101, 28997, … 5110] │\n",
       "│ 5abff8c95542994516f4555c ┆ [CLS] [Q] The person where loc… ┆ [101, 28997, … 103]  │\n",
       "│ 5adec8ad55429975fa854f8f ┆ [CLS] [Q] The actor who played… ┆ [101, 28997, … 103]  │\n",
       "└──────────────────────────┴─────────────────────────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = (\n",
    "    queries\n",
    "    .with_columns(\n",
    "        pl.Series(queries_tokenized['input_ids']).alias('tok_ids')\n",
    "    )\n",
    ")\n",
    "\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries.write_parquet(conf['PROCESSED']['query'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
